"""
å­—å¹•åœé¡¿åŒ¹é…å·¥å…·
ç”¨é€”: æ£€æµ‹è¯­éŸ³æ–‡ä»¶çš„åœé¡¿é—´éš™ï¼Œè‡ªåŠ¨è°ƒæ•´å­—å¹•æ—¶é—´ä»¥åŒ¹é…è¯­éŸ³èŠ‚å¥
"""

import sys
import os
import json
import threading
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple, Optional

import numpy as np
from scipy import signal as scipy_signal
from scipy.io import wavfile

from PySide6.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit,
    QLabel, QLineEdit, QFileDialog, QSpinBox, QDoubleSpinBox, QCheckBox,
    QComboBox, QFrame, QScrollArea, QProgressBar, QMessageBox, QGridLayout,
    QSizePolicy
)
from PySide6.QtCore import QThread, Signal, Qt, QPropertyAnimation, QEasingCurve
from PySide6.QtGui import QFont, QPalette, QFontDatabase, QIcon


# ============================================================================
# å·¥å…·å‡½æ•°ä¸æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class Silence:
    """é™éŸ³æ®µä¿¡æ¯"""
    start: float  # ç§’
    end: float    # ç§’
    duration: float

    @property
    def center(self) -> float:
        return (self.start + self.end) / 2


class SRTSubtitle:
    """SRT å­—å¹•æ¡ç›®"""
    def __init__(self, index: int, start: float, end: float, text: str):
        self.index = index
        self.start = start  # ç§’
        self.end = end      # ç§’
        self.text = text

    def shift(self, delta: float):
        """æ•´ä½“æ—¶ç§»"""
        self.start += delta
        self.end += delta

    def to_srt_time(self, seconds: float) -> str:
        """è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ HH:MM:SS,mmm"""
        total_ms = int(seconds * 1000)
        h = total_ms // 3600000
        m = (total_ms % 3600000) // 60000
        s = (total_ms % 60000) // 1000
        ms = total_ms % 1000
        return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"

    def to_srt_line(self) -> str:
        """ç”Ÿæˆ SRT æ ¼å¼çš„ä¸€è¡Œ"""
        return f"{self.index}\n{self.to_srt_time(self.start)} --> {self.to_srt_time(self.end)}\n{self.text}\n\n"


# ============================================================================
# éŸ³é¢‘åˆ†ææ¨¡å—
# ============================================================================

class AudioAnalyzer:
    """éŸ³é¢‘åˆ†æå¼•æ“"""

    def __init__(self, audio_path: str, threshold_db: float = -40, min_silence_duration: float = 0.01):
        """
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            threshold_db: éŸ³é‡é˜ˆå€¼ï¼ˆdBï¼‰ï¼Œä½äºæ­¤å€¼è§†ä¸ºé™éŸ³
            min_silence_duration: æœ€å°é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        self.audio_path = audio_path
        self.threshold_db = threshold_db
        self.min_silence_duration = min_silence_duration
        self.silences: List[Silence] = []
        self.sr = None
        self.duration = 0.0

    def analyze(self) -> List[Silence]:
        """åˆ†æéŸ³é¢‘ï¼Œè¿”å›é™éŸ³æ®µåˆ—è¡¨"""
        try:
            # è¯»å–éŸ³é¢‘
            sr, audio_data = wavfile.read(self.audio_path)
            self.sr = sr

            # è½¬æ¢ä¸ºå•å£°é“
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)

            # å½’ä¸€åŒ–åˆ° [-1, 1]
            if audio_data.dtype != np.float32 and audio_data.dtype != np.float64:
                audio_data = audio_data.astype(np.float32) / np.iinfo(audio_data.dtype).max

            self.duration = len(audio_data) / sr

            # è®¡ç®—ç¬æ—¶èƒ½é‡
            frame_length = int(sr * 0.01)  # 10ms å¸§
            hop_length = frame_length // 2
            energy = self._compute_energy(audio_data, frame_length, hop_length)

            # è½¬æ¢ä¸º dB
            energy_db = 20 * np.log10(energy + 1e-10)

            # æ£€æµ‹é™éŸ³å¸§
            silent_mask = energy_db < self.threshold_db

            # è¿æ¥ç›¸é‚»é™éŸ³å¸§
            self.silences = self._merge_silences(silent_mask, hop_length, sr)

            return self.silences

        except Exception as e:
            raise RuntimeError(f"éŸ³é¢‘åˆ†æå¤±è´¥: {str(e)}")

    @staticmethod
    def _compute_energy(audio: np.ndarray, frame_length: int, hop_length: int) -> np.ndarray:
        """è®¡ç®—æ¯å¸§çš„èƒ½é‡"""
        n_frames = 1 + (len(audio) - frame_length) // hop_length
        energy = np.zeros(n_frames)

        for i in range(n_frames):
            start = i * hop_length
            end = start + frame_length
            frame = audio[start:end]
            energy[i] = np.sqrt(np.mean(frame ** 2))

        return energy

    def _merge_silences(self, silent_mask: np.ndarray, hop_length: int, sr: int) -> List[Silence]:
        """åˆå¹¶ç›¸é‚»çš„é™éŸ³å¸§"""
        silences = []
        in_silence = False
        silence_start = 0

        for i, is_silent in enumerate(silent_mask):
            time = i * hop_length / sr

            if is_silent and not in_silence:
                silence_start = time
                in_silence = True
            elif not is_silent and in_silence:
                silence_end = time
                duration = silence_end - silence_start

                # åªä¿ç•™è¶³å¤Ÿé•¿çš„é™éŸ³æ®µ
                if duration >= self.min_silence_duration:
                    silences.append(Silence(silence_start, silence_end, duration))

                in_silence = False

        # å¤„ç†æœ€åä¸€ä¸ªé™éŸ³æ®µ
        if in_silence:
            silence_end = len(silent_mask) * hop_length / sr
            duration = silence_end - silence_start
            if duration >= self.min_silence_duration:
                silences.append(Silence(silence_start, silence_end, duration))

        return silences


# ============================================================================
# SRT å¤„ç†æ¨¡å—
# ============================================================================

class SRTParser:
    """SRT å­—å¹•è§£æä¸å¤„ç†"""

    @staticmethod
    def parse_srt_time(time_str: str) -> float:
        """è§£æ SRT æ—¶é—´æ ¼å¼ HH:MM:SS,mmm ä¸ºç§’"""
        parts = time_str.replace(',', '.').split(':')
        hours = int(parts[0])
        minutes = int(parts[1])
        seconds = float(parts[2])
        return hours * 3600 + minutes * 60 + seconds

    @staticmethod
    def load(filepath: str) -> List[SRTSubtitle]:
        """åŠ è½½ SRT æ–‡ä»¶"""
        subtitles = []
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read().strip()

        blocks = content.split('\n\n')
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) < 3:
                continue

            try:
                index = int(lines[0])
                time_range = lines[1].split(' --> ')
                start = SRTParser.parse_srt_time(time_range[0].strip())
                end = SRTParser.parse_srt_time(time_range[1].strip())
                text = '\n'.join(lines[2:])

                subtitles.append(SRTSubtitle(index, start, end, text))
            except Exception:
                continue

        return subtitles

    @staticmethod
    def save(filepath: str, subtitles: List[SRTSubtitle]):
        """ä¿å­˜ SRT æ–‡ä»¶"""
        lines = []
        for i, sub in enumerate(subtitles, 1):
            sub.index = i
            lines.append(sub.to_srt_line())
        
        with open(filepath, 'w', encoding='utf-8') as f:
            # å°†æ‰€æœ‰è¡Œè¿æ¥ï¼Œç„¶åç§»é™¤æœ€åä¸€ä¸ªå¤šä½™çš„ç©ºè¡Œ
            content = ''.join(lines).rstrip() + '\n'
            f.write(content)


# ============================================================================
# åŒ¹é…ç®—æ³•æ¨¡å—
# ============================================================================

class SubtitleMatcher:
    """å­—å¹•ä¸åœé¡¿åŒ¹é…å¼•æ“"""

    @staticmethod
    def match_subtitles(subtitles: List[SRTSubtitle], silences: List[Silence]) -> Tuple[List[SRTSubtitle], str]:
        """
        æ ¹æ®åœé¡¿é—´éš™çš„å‡ºå…¥ç‚¹è°ƒæ•´å­—å¹•æ—¶é—´
        
        è§„åˆ™:
        å­—å¹•æ•°: n, é—´éš™æ•°: m
        
        æ ‡å‡†æƒ…å†µ (m = n+1): é¦–å°¾éƒ½æœ‰é—´éš™
        - é—´éš™[i]çš„å‡ºç‚¹(end) = å­—å¹•[i]çš„å…¥ç‚¹(start)
        - é—´éš™[i+1]çš„å…¥ç‚¹(start) = å­—å¹•[i]çš„å‡ºç‚¹(end)
        
        å•ç«¯æƒ…å†µ (m = n): é¦–æˆ–å°¾åªæœ‰ä¸€ç«¯æœ‰é—´éš™
        - éœ€è¦æ ¹æ®è¯­éŸ³æ—¶é•¿å’Œé—´éš™æ—¶é•¿åˆ¤æ–­
        - ç„¶ååšå‡ºç›¸åº”çš„åŒ¹é…
        
        æ— ç«¯æƒ…å†µ (m = n-1): é¦–å°¾éƒ½æ²¡æœ‰é—´éš™
        - ç¬¬ä¸€æ®µå­—å¹•çš„å…¥ç‚¹å’Œæœ€åä¸€æ®µå­—å¹•çš„å‡ºç‚¹ä¸éœ€è¦ä¿®æ”¹

        Args:
            subtitles: åŸå§‹å­—å¹•åˆ—è¡¨
            silences: æ£€æµ‹åˆ°çš„åœé¡¿åˆ—è¡¨

        Returns:
            (è°ƒæ•´åçš„å­—å¹•åˆ—è¡¨, è¯¦ç»†æ—¥å¿—å­—ç¬¦ä¸²)
        """
        log_lines = []
        
        if not subtitles or not silences:
            log_lines.append("âš  å­—å¹•æˆ–åœé¡¿åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•åŒ¹é…")
            return subtitles, "\n".join(log_lines)

        n = len(subtitles)
        m = len(silences)
        
        log_lines.append(f"{'=' * 70}")
        log_lines.append(f"å­—å¹•åŒ¹é…åˆ†æ")
        log_lines.append(f"{'=' * 70}")
        log_lines.append(f"å­—å¹•æ•°é‡ (n): {n}")
        log_lines.append(f"é—´éš™æ•°é‡ (m): {m}")
        log_lines.append(f"å…³ç³»: m - n = {m - n}")
        log_lines.append("")
        
        # ç¡®å®šæƒ…å†µç±»å‹å¹¶åŒ¹é…
        if m == n + 1:
            case_type = "æ ‡å‡†æƒ…å†µ: m = n + 1 (é¦–å°¾éƒ½æœ‰é—´éš™)"
            log_lines.append(f"âœ“ {case_type}")
            log_lines.append("  è§„åˆ™: é—´éš™å‡ºç‚¹â†’å­—å¹•å…¥ç‚¹, é—´éš™å…¥ç‚¹â†’å­—å¹•å‡ºç‚¹")
            adjusted = SubtitleMatcher._match_standard(subtitles, silences, log_lines)
        
        elif m == n:
            case_type = "å•ç«¯æƒ…å†µ: m = n (é¦–æˆ–å°¾åªæœ‰ä¸€ç«¯æœ‰é—´éš™)"
            log_lines.append(f"âœ“ {case_type}")
            log_lines.append("  åˆ¤æ–­é€»è¾‘: æ ¹æ®è¯­éŸ³å’Œé—´éš™æ—¶é•¿åˆ¤æ–­é¦–éƒ¨æˆ–å°¾éƒ¨")
            adjusted = SubtitleMatcher._match_single_end(subtitles, silences, log_lines)
        
        elif m == n - 1:
            case_type = "æ— ç«¯æƒ…å†µ: m = n - 1 (é¦–å°¾éƒ½æ²¡æœ‰é—´éš™)"
            log_lines.append(f"âœ“ {case_type}")
            log_lines.append("  è§„åˆ™: é¦–å°¾å­—å¹•å…¥å‡ºç‚¹ä¸ä¿®æ”¹ï¼Œä¸­é—´å­—å¹•æ˜ å°„åˆ°é—´éš™")
            adjusted = SubtitleMatcher._match_no_ends(subtitles, silences, log_lines)
        
        else:
            log_lines.append(f"âš  ç‰¹æ®Šæƒ…å†µ: m={m}, n={n}, å…³ç³»ä¸ç¬¦åˆé¢„æœŸ")
            log_lines.append("  ä½¿ç”¨é€šç”¨æ¯”ä¾‹åˆ†é…æ–¹æ³•")
            adjusted = SubtitleMatcher._match_fallback(subtitles, silences, log_lines)
        
        log_lines.append("")
        log_lines.append(f"{'=' * 70}")
        log_lines.append("è°ƒæ•´åçš„å­—å¹•è¯¦æƒ…:")
        log_lines.append(f"{'=' * 70}")
        for i, sub in enumerate(adjusted, 1):
            log_lines.append(f"{i}. [{sub.index}] {sub.to_srt_time(sub.start)} --> {sub.to_srt_time(sub.end)}")
            log_lines.append(f"   æ—¶é•¿: {sub.end - sub.start:.3f}s | æ–‡æœ¬: {sub.text[:60]}")
        
        return adjusted, "\n".join(log_lines)

    @staticmethod
    def _match_standard(subtitles: List[SRTSubtitle], silences: List[Silence], log_lines: list) -> List[SRTSubtitle]:
        """
        æ ‡å‡†æƒ…å†µ: m = n + 1 (é¦–å°¾éƒ½æœ‰é—´éš™)
        
        è§„åˆ™:
        - é—´éš™[i]çš„å‡ºç‚¹(end) = å­—å¹•[i]çš„å…¥ç‚¹(start)
        - é—´éš™[i+1]çš„å…¥ç‚¹(start) = å­—å¹•[i]çš„å‡ºç‚¹(end)
        """
        log_lines.append("")
        log_lines.append(f"{'â”€' * 70}")
        log_lines.append("æ ‡å‡†æƒ…å†µå¤„ç†:")
        log_lines.append(f"{'â”€' * 70}")
        
        adjusted = []
        
        for i, sub in enumerate(subtitles):
            # å­—å¹•[i]åº”è¯¥åœ¨é—´éš™[i]å’Œé—´éš™[i+1]ä¹‹é—´
            gap_out = silences[i]      # è¿™ä¸ªé—´éš™çš„å‡ºç‚¹ = å­—å¹•å…¥ç‚¹
            gap_in = silences[i + 1]   # ä¸‹ä¸€ä¸ªé—´éš™çš„å…¥ç‚¹ = å­—å¹•å‡ºç‚¹
            
            new_start = gap_out.end
            new_end = gap_in.start
            
            log_lines.append(f"å­—å¹• {i+1}:")
            log_lines.append(f"  åŸå§‹: {sub.to_srt_time(sub.start)} --> {sub.to_srt_time(sub.end)}")
            log_lines.append(f"  æ˜ å°„: é—´éš™[{i}].end={SubtitleMatcher._format_time(gap_out.end)}")
            log_lines.append(f"        é—´éš™[{i+1}].start={SubtitleMatcher._format_time(gap_in.start)}")
            log_lines.append(f"  è°ƒæ•´: {SubtitleMatcher._format_time(new_start)} --> {SubtitleMatcher._format_time(new_end)}")
            log_lines.append(f"  æ—¶é•¿: {new_end - new_start:.3f}s")
            
            new_sub = SRTSubtitle(sub.index, new_start, new_end, sub.text)
            adjusted.append(new_sub)
        
        return adjusted

    @staticmethod
    def _match_single_end(subtitles: List[SRTSubtitle], silences: List[Silence], log_lines: list) -> List[SRTSubtitle]:
        """
        å•ç«¯æƒ…å†µ: m = n (é¦–æˆ–å°¾åªæœ‰ä¸€ç«¯æœ‰é—´éš™)
        
        åˆ¤æ–­é€»è¾‘:
        - è®¡ç®—æ€»é—´éš™æ—¶é•¿ vs è¯­éŸ³ä¸­é—´éš™ä»¥å¤–çš„éƒ¨åˆ†
        - å¦‚æœç¬¬ä¸€ä¸ªé—´éš™å¾ˆé åï¼Œè¯´æ˜å¤´éƒ¨æ— é—´éš™
        - å¦‚æœæœ€åä¸€ä¸ªé—´éš™å¾ˆé å‰ï¼Œè¯´æ˜å°¾éƒ¨æ— é—´éš™
        """
        log_lines.append("")
        log_lines.append(f"{'â”€' * 70}")
        log_lines.append("å•ç«¯æƒ…å†µå¤„ç†:")
        log_lines.append(f"{'â”€' * 70}")
        
        # åˆ†æé—´éš™åˆ†å¸ƒ
        if len(silences) > 0:
            first_silence_start = silences[0].start
            last_silence_end = silences[-1].end
            
            # å¯å‘å¼åˆ¤æ–­: å¦‚æœç¬¬ä¸€ä¸ªé—´éš™è·ç¦»å¼€å¤´è¾ƒè¿œï¼Œè¯´æ˜å‰é¢æœ‰å†…å®¹ï¼ˆå¤´éƒ¨æ— é—´éš™ï¼‰
            # å¦‚æœæœ€åä¸€ä¸ªé—´éš™ä¸æ˜¯å¾ˆé åï¼Œè¯´æ˜åé¢æœ‰å†…å®¹ï¼ˆå°¾éƒ¨æ— é—´éš™ï¼‰
            has_head_gap = first_silence_start < 2.0  # å‡è®¾2ç§’å†…æœ‰ç¬¬ä¸€ä¸ªé—´éš™
            has_tail_gap = last_silence_end > 5.0  # å‡è®¾é åæœ‰æœ€åä¸€ä¸ªé—´éš™ï¼ˆç®€åŒ–ï¼‰
        else:
            has_head_gap = False
            has_tail_gap = False
        
        log_lines.append(f"ç¬¬ä¸€ä¸ªé—´éš™å¼€å§‹æ—¶é—´: {silences[0].start:.3f}s")
        log_lines.append(f"æœ€åä¸€ä¸ªé—´éš™ç»“æŸæ—¶é—´: {silences[-1].end:.3f}s")
        log_lines.append(f"åˆ¤å®š: å¤´éƒ¨{'æœ‰' if has_head_gap else 'æ— '}é—´éš™, å°¾éƒ¨{'æœ‰' if has_tail_gap else 'æ— '}é—´éš™")
        log_lines.append("")
        
        adjusted = []
        
        if has_head_gap and not has_tail_gap:
            # å¤´éƒ¨æœ‰é—´éš™ï¼Œå°¾éƒ¨æ— é—´éš™
            log_lines.append("ç­–ç•¥: å¤´éƒ¨æœ‰é—´éš™ï¼Œå°¾éƒ¨æ— é—´éš™")
            for i in range(len(subtitles) - 1):
                # å‰n-1ä¸ªå­—å¹•
                new_start = silences[i].end
                new_end = silences[i + 1].start
                new_sub = SRTSubtitle(subtitles[i].index, new_start, new_end, subtitles[i].text)
                adjusted.append(new_sub)
                log_lines.append(f"å­—å¹• {i+1}: {SubtitleMatcher._format_time(new_start)} --> {SubtitleMatcher._format_time(new_end)}")
            
            # æœ€åä¸€ä¸ªå­—å¹•ä¿æŒåŸå§‹é•¿åº¦ï¼Œä»æœ€åé—´éš™æœ«å°¾å¼€å§‹
            last_sub = subtitles[-1]
            last_start = silences[-1].end
            last_end = last_start + (last_sub.end - last_sub.start)
            new_sub = SRTSubtitle(last_sub.index, last_start, last_end, last_sub.text)
            adjusted.append(new_sub)
            log_lines.append(f"å­—å¹• {len(subtitles)}: {SubtitleMatcher._format_time(last_start)} --> {SubtitleMatcher._format_time(last_end)} (å°¾éƒ¨æ— é—´éš™)")
        
        else:  # é»˜è®¤: å°¾éƒ¨æœ‰é—´éš™ï¼Œå¤´éƒ¨æ— é—´éš™
            # å¤´éƒ¨æ— é—´éš™ï¼Œå°¾éƒ¨æœ‰é—´éš™
            log_lines.append("ç­–ç•¥: å¤´éƒ¨æ— é—´éš™ï¼Œå°¾éƒ¨æœ‰é—´éš™")
            
            # ç¬¬ä¸€ä¸ªå­—å¹•ä¿æŒåŸå§‹é•¿åº¦ï¼Œåˆ°ç¬¬ä¸€ä¸ªé—´éš™å¼€å§‹
            first_sub = subtitles[0]
            first_end = silences[0].start
            first_start = first_end - (first_sub.end - first_sub.start)
            new_sub = SRTSubtitle(first_sub.index, first_start, first_end, first_sub.text)
            adjusted.append(new_sub)
            log_lines.append(f"å­—å¹• 1: {SubtitleMatcher._format_time(first_start)} --> {SubtitleMatcher._format_time(first_end)} (å¤´éƒ¨æ— é—´éš™)")
            
            # åç»­å­—å¹•
            for i in range(1, len(subtitles)):
                new_start = silences[i - 1].end
                new_end = silences[i].start
                new_sub = SRTSubtitle(subtitles[i].index, new_start, new_end, subtitles[i].text)
                adjusted.append(new_sub)
                log_lines.append(f"å­—å¹• {i+1}: {SubtitleMatcher._format_time(new_start)} --> {SubtitleMatcher._format_time(new_end)}")
        
        return adjusted

    @staticmethod
    def _match_no_ends(subtitles: List[SRTSubtitle], silences: List[Silence], log_lines: list) -> List[SRTSubtitle]:
        """
        æ— ç«¯æƒ…å†µ: m = n - 1 (é¦–å°¾éƒ½æ²¡æœ‰é—´éš™)
        
        è§„åˆ™:
        - ç¬¬ä¸€æ®µå­—å¹•çš„å…¥ç‚¹(start)ä¸ä¿®æ”¹
        - æœ€åä¸€æ®µå­—å¹•çš„å‡ºç‚¹(end)ä¸ä¿®æ”¹
        - ä¸­é—´n-1æ®µå­—å¹•æ˜ å°„åˆ°mä¸ªé—´éš™
        """
        log_lines.append("")
        log_lines.append(f"{'â”€' * 70}")
        log_lines.append("æ— ç«¯æƒ…å†µå¤„ç†:")
        log_lines.append(f"{'â”€' * 70}")
        
        adjusted = []
        
        # ç¬¬ä¸€ä¸ªå­—å¹•ä¿æŒåŸå§‹å…¥ç‚¹
        first_sub = subtitles[0]
        if len(silences) > 0:
            first_end = silences[0].start
        else:
            first_end = first_sub.end
        
        new_sub = SRTSubtitle(first_sub.index, first_sub.start, first_end, first_sub.text)
        adjusted.append(new_sub)
        log_lines.append(f"å­—å¹• 1: {SubtitleMatcher._format_time(first_sub.start)} --> {SubtitleMatcher._format_time(first_end)} (é¦–éƒ¨æ— é—´éš™ï¼Œå…¥ç‚¹ä¸ä¿®æ”¹)")
        
        # ä¸­é—´å­—å¹•
        for i in range(1, len(subtitles) - 1):
            gap_idx = i - 1
            new_start = silences[gap_idx].end
            new_end = silences[gap_idx + 1].start if gap_idx + 1 < len(silences) else subtitles[-1].start
            
            new_sub = SRTSubtitle(subtitles[i].index, new_start, new_end, subtitles[i].text)
            adjusted.append(new_sub)
            log_lines.append(f"å­—å¹• {i+1}: {SubtitleMatcher._format_time(new_start)} --> {SubtitleMatcher._format_time(new_end)}")
        
        # æœ€åä¸€ä¸ªå­—å¹•ä¿æŒåŸå§‹å‡ºç‚¹
        last_sub = subtitles[-1]
        if len(silences) > 0:
            last_start = silences[-1].end
        else:
            last_start = last_sub.start
        
        new_sub = SRTSubtitle(last_sub.index, last_start, last_sub.end, last_sub.text)
        adjusted.append(new_sub)
        log_lines.append(f"å­—å¹• {len(subtitles)}: {SubtitleMatcher._format_time(last_start)} --> {SubtitleMatcher._format_time(last_sub.end)} (å°¾éƒ¨æ— é—´éš™ï¼Œå‡ºç‚¹ä¸ä¿®æ”¹)")
        
        return adjusted

    @staticmethod
    def _match_fallback(subtitles: List[SRTSubtitle], silences: List[Silence], log_lines: list) -> List[SRTSubtitle]:
        """
        Fallback: å…¶ä»–ç‰¹æ®Šæƒ…å†µï¼ŒæŒ‰æ¯”ä¾‹åˆ†é…
        """
        log_lines.append("")
        log_lines.append(f"{'â”€' * 70}")
        log_lines.append("Fallback å¤„ç† (æ¯”ä¾‹åˆ†é…):")
        log_lines.append(f"{'â”€' * 70}")
        
        n = len(subtitles)
        m = len(silences)
        
        if m > n:
            # é—´éš™å¤šäºå­—å¹•: é€‰æ‹©å‡åŒ€åˆ†å¸ƒçš„é—´éš™å­é›†
            log_lines.append(f"é—´éš™è¿‡å¤š({m} > {n})ï¼Œé€‰æ‹©å‡åŒ€åˆ†å¸ƒçš„ {n} ä¸ªé—´éš™")
            step = m / n
            adjusted = []
            for i, sub in enumerate(subtitles):
                idx = int(i * step)
                idx = min(idx, len(silences) - 1)
                gap = silences[idx]
                new_start = gap.start
                new_end = gap.end
                new_sub = SRTSubtitle(sub.index, new_start, new_end, sub.text)
                adjusted.append(new_sub)
                log_lines.append(f"å­—å¹• {i+1}: {SubtitleMatcher._format_time(new_start)} --> {SubtitleMatcher._format_time(new_end)} (ä½¿ç”¨é—´éš™ {idx})")
        else:
            # å­—å¹•å¤šäºé—´éš™: å°½é‡åˆ†é…
            log_lines.append(f"å­—å¹•è¿‡å¤š({n} > {m})ï¼ŒæŒ‰åˆ†å¸ƒåˆ†é…")
            step = n / m
            adjusted = []
            for i, sub in enumerate(subtitles):
                gap_idx = int(i / step)
                gap_idx = min(gap_idx, len(silences) - 1)
                gap = silences[gap_idx]
                
                # åœ¨è¿™ä¸ªé—´éš™å†…çš„ä½ç½®
                new_start = gap.start + (i % step) / step * (gap.end - gap.start)
                new_end = new_start + (sub.end - sub.start)
                
                new_sub = SRTSubtitle(sub.index, new_start, new_end, sub.text)
                adjusted.append(new_sub)
                log_lines.append(f"å­—å¹• {i+1}: {SubtitleMatcher._format_time(new_start)} --> {SubtitleMatcher._format_time(new_end)}")
        
        return adjusted

    @staticmethod
    def _format_time(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ä¸ºå­—ç¬¦ä¸²"""
        total_ms = int(seconds * 1000)
        h = total_ms // 3600000
        m = (total_ms % 3600000) // 60000
        s = (total_ms % 60000) // 1000
        ms = total_ms % 1000
        return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"


# ============================================================================
# å¯æŠ˜å é¢æ¿ç»„ä»¶
# ============================================================================

class CollapsibleBox(QWidget):
    """å¯æŠ˜å çš„è®¾ç½®é¢æ¿"""

    def __init__(self, title: str = "", parent=None, duration: int = 250):
        super().__init__(parent)
        self._title = title

        # ä¿è¯æŠ˜å æ—¶ä¸å æ®å¤šä½™ç©ºé—´ï¼Œé…åˆä¸‹æ–¹å¼¹ç°§å¯è´´é¡¶
        self.setSizePolicy(QSizePolicy.Preferred, QSizePolicy.Maximum)

        # æ ‡é¢˜æŒ‰é’®
        self.toggle_button = QPushButton()
        f = self.toggle_button.font()
        f.setBold(True)
        self.toggle_button.setFont(f)
        self.toggle_button.setCheckable(True)
        self.toggle_button.setChecked(False)
        self.toggle_button.setMaximumHeight(32)
        self.toggle_button.setCursor(Qt.PointingHandCursor)

        # å†…å®¹åŒº
        self.content_area = QFrame()
        self.content_area.setFrameShape(QFrame.StyledPanel)
        self.content_area.setMaximumHeight(0)
        self.content_area.setMinimumHeight(0)

        # åŠ¨ç”»
        self.anim = QPropertyAnimation(self.content_area, b"maximumHeight")
        self.anim.setDuration(duration)
        self.anim.setEasingCurve(QEasingCurve.InOutCubic)

        # å¸ƒå±€
        lay = QVBoxLayout(self)
        lay.setContentsMargins(0, 0, 0, 0)
        lay.setSpacing(2)
        lay.addWidget(self.toggle_button)
        lay.addWidget(self.content_area)

        self.toggle_button.clicked.connect(self._on_toggled)
        self._update_arrow(False)

    def setContentLayout(self, layout):
        """è®¾ç½®å†…å®¹å¸ƒå±€"""
        old = self.content_area.layout()
        if old:
            while old.count():
                it = old.takeAt(0)
                w = it.widget()
                if w:
                    w.setParent(None)

        self.content_area.setLayout(layout)

    def _on_toggled(self, checked):
        """å¤„ç†å±•å¼€/æ”¶èµ·"""
        self._update_arrow(checked)
        layout = self.content_area.layout()
        h = layout.sizeHint().height() if layout else 0

        self.anim.stop()
        self.anim.setStartValue(self.content_area.maximumHeight())
        self.anim.setEndValue(h if checked else 0)
        self.anim.start()

    def _update_arrow(self, expanded):
        """æ›´æ–°ç®­å¤´"""
        arrow = "â–¼" if expanded else "â–º"
        self.toggle_button.setText(f"{arrow} {self._title}")


# ============================================================================
# åå°å·¥ä½œçº¿ç¨‹
# ============================================================================

class AnalysisWorker(QThread):
    """åå°åˆ†æçº¿ç¨‹"""
    progress = Signal(str)
    finished = Signal(list)  # è¿”å› silences åˆ—è¡¨
    error = Signal(str)

    def __init__(self, audio_path: str, threshold_db: float, min_silence: float):
        super().__init__()
        self.audio_path = audio_path
        self.threshold_db = threshold_db
        self.min_silence = min_silence

    def run(self):
        try:
            self.progress.emit("æ­£åœ¨åˆ†æéŸ³é¢‘æ–‡ä»¶...")
            analyzer = AudioAnalyzer(self.audio_path, self.threshold_db, self.min_silence)
            silences = analyzer.analyze()
            self.progress.emit(f"åˆ†æå®Œæˆï¼æ£€æµ‹åˆ° {len(silences)} ä¸ªåœé¡¿")
            self.finished.emit(silences)
        except Exception as e:
            self.error.emit(str(e))


class MatchingWorker(QThread):
    """åå°åŒ¹é…çº¿ç¨‹"""
    progress = Signal(str)
    finished = Signal(list, str)  # è¿”å›(è°ƒæ•´åçš„å­—å¹•åˆ—è¡¨, è¯¦ç»†æ—¥å¿—)
    error = Signal(str)

    def __init__(self, srt_path: str, silences: List[Silence]):
        super().__init__()
        self.srt_path = srt_path
        self.silences = silences

    def run(self):
        try:
            self.progress.emit("æ­£åœ¨åŠ è½½å­—å¹•...")
            subtitles = SRTParser.load(self.srt_path)
            self.progress.emit(f"æ­£åœ¨åŒ¹é… {len(subtitles)} æ¡å­—å¹•ä¸ {len(self.silences)} ä¸ªåœé¡¿...")
            adjusted, log = SubtitleMatcher.match_subtitles(subtitles, self.silences)
            self.progress.emit("åŒ¹é…å®Œæˆï¼")
            self.finished.emit(adjusted, log)
        except Exception as e:
            self.error.emit(str(e))


# ============================================================================
# ä¸»ç•Œé¢
# ============================================================================

class SubtitlePauseMatcherUI(QWidget):
    """å­—å¹•åœé¡¿åŒ¹é…å·¥å…· UI"""

    def __init__(self):
        super().__init__()
        self.setWindowTitle("å­—å¹•åœé¡¿åŒ¹é…å·¥å…·")
        self.setGeometry(100, 100, 900, 700)

        # å½“å‰çŠ¶æ€
        self.audio_path = None
        self.srt_path = None
        self.current_silences: List[Silence] = []
        self.current_subtitles: List[SRTSubtitle] = []

        # å·¥ä½œçº¿ç¨‹
        self.analysis_worker = None
        self.matching_worker = None

        self._init_ui()
        self._connect_signals()

    def _init_ui(self):
        """åˆå§‹åŒ– UI"""
        root_layout = QVBoxLayout(self)
        root_layout.setContentsMargins(8, 8, 8, 8)
        root_layout.setSpacing(4)

        # ====== çŠ¶æ€è¡Œ ======
        status_layout = QHBoxLayout()
        status_layout.setContentsMargins(0, 0, 0, 0)

        self.status_label = QLabel("å°±ç»ª")
        status_layout.addWidget(self.status_label, 1)

        self.open_output_btn = QPushButton("ğŸ“‚ æ‰“å¼€è¾“å‡º")
        self.open_output_btn.setMaximumWidth(100)
        self.open_output_btn.clicked.connect(self._open_output)
        status_layout.addWidget(self.open_output_btn)

        root_layout.addLayout(status_layout)

        # ====== æ–‡ä»¶é€‰æ‹©åŒº ======
        file_layout = QGridLayout()
        file_layout.setContentsMargins(0, 0, 0, 0)
        file_layout.setSpacing(4)

        file_layout.addWidget(QLabel("è¯­éŸ³æ–‡ä»¶:"), 0, 0)
        self.audio_path_edit = QLineEdit()
        self.audio_path_edit.setReadOnly(True)
        file_layout.addWidget(self.audio_path_edit, 0, 1)
        audio_btn = QPushButton("é€‰æ‹©")
        audio_btn.setMaximumWidth(80)
        audio_btn.clicked.connect(self._select_audio)
        file_layout.addWidget(audio_btn, 0, 2)

        file_layout.addWidget(QLabel("å­—å¹•æ–‡ä»¶:"), 1, 0)
        self.srt_path_edit = QLineEdit()
        self.srt_path_edit.setReadOnly(True)
        file_layout.addWidget(self.srt_path_edit, 1, 1)
        srt_btn = QPushButton("é€‰æ‹©")
        srt_btn.setMaximumWidth(80)
        srt_btn.clicked.connect(self._select_srt)
        file_layout.addWidget(srt_btn, 1, 2)

        root_layout.addLayout(file_layout)

        # ====== è®¾ç½®é¢æ¿ ======
        settings_box = CollapsibleBox("âš™ï¸ éŸ³é¢‘åˆ†æè®¾ç½®", duration=250)
        settings_layout = QGridLayout()
        settings_layout.setSpacing(6)

        settings_layout.addWidget(QLabel("éŸ³é‡é˜ˆå€¼ (dB):"), 0, 0)
        self.threshold_spin = QSpinBox()
        self.threshold_spin.setRange(-80, 0)
        self.threshold_spin.setValue(-40)
        settings_layout.addWidget(self.threshold_spin, 0, 1)

        settings_layout.addWidget(QLabel("æœ€å°åœé¡¿æ—¶é•¿ (ç§’):"), 1, 0)
        self.min_silence_spin = QDoubleSpinBox()
        self.min_silence_spin.setRange(0.01, 10.0)
        self.min_silence_spin.setSingleStep(0.01)
        self.min_silence_spin.setValue(0.01)
        settings_layout.addWidget(self.min_silence_spin, 1, 1)

        settings_box.setContentLayout(settings_layout)
        root_layout.addWidget(settings_box)

        # ====== æ“ä½œæŒ‰é’®è¡Œ ======
        action_layout = QHBoxLayout()
        action_layout.setSpacing(6)

        self.analyze_btn = QPushButton("ğŸ” åˆ†æéŸ³é¢‘")
        self.analyze_btn.clicked.connect(self._analyze_audio)
        action_layout.addWidget(self.analyze_btn)

        self.match_btn = QPushButton("ğŸ”— åŒ¹é…å­—å¹•")
        self.match_btn.setEnabled(False)
        self.match_btn.clicked.connect(self._match_subtitles)
        action_layout.addWidget(self.match_btn)

        self.export_btn = QPushButton("ğŸ’¾ å¯¼å‡ºå­—å¹•")
        self.export_btn.setEnabled(False)
        self.export_btn.clicked.connect(self._export_subtitles)
        action_layout.addWidget(self.export_btn)

        self.reset_btn = QPushButton("ğŸ”„ é‡ç½®")
        self.reset_btn.clicked.connect(self._reset)
        action_layout.addWidget(self.reset_btn)

        # è‡ªåŠ¨æ‰§è¡Œåæ— éœ€æ‰‹åŠ¨ç‚¹å‡»ï¼ŒæŒ‰é’®é»˜è®¤éšè—ï¼ˆä¿ç•™é€»è¾‘å¤‡ç”¨ï¼‰
        self.analyze_btn.setVisible(False)
        self.match_btn.setVisible(False)
        root_layout.addLayout(action_layout)

        # ====== è¿›åº¦æ¡ ======
        self.progress_bar = QProgressBar()
        self.progress_bar.setMaximum(0)  # ä¸ç¡®å®šæ¨¡å¼
        self.progress_bar.setVisible(False)
        root_layout.addWidget(self.progress_bar)

        # ====== åˆå¹¶åçš„â€œåˆ†æç»“æœ(å«æ—¥å¿—)â€ æŠ˜å é¢æ¿ ======
        info_box = CollapsibleBox("ğŸ“Š åˆ†æç»“æœ", duration=250)
        info_layout = QGridLayout()
        info_layout.setSpacing(6)

        info_layout.addWidget(QLabel("æ£€æµ‹åˆ°çš„åœé¡¿æ•°:"), 0, 0)
        self.silence_count_label = QLabel("0")
        info_layout.addWidget(self.silence_count_label, 0, 1)

        info_layout.addWidget(QLabel("æ€»åœé¡¿æ—¶é•¿:"), 1, 0)
        self.total_silence_label = QLabel("0.0s")
        info_layout.addWidget(self.total_silence_label, 1, 1)

        info_layout.addWidget(QLabel("å­—å¹•æ¡æ•°:"), 2, 0)
        self.subtitle_count_label = QLabel("0")
        info_layout.addWidget(self.subtitle_count_label, 2, 1)

        info_layout.addWidget(QLabel("åŸå§‹æ—¶é•¿:"), 3, 0)
        self.original_duration_label = QLabel("0.0s")
        info_layout.addWidget(self.original_duration_label, 3, 1)

        # æ—¥å¿—åŒºï¼ˆç§»å…¥åˆ†æç»“æœé¢æ¿å†…ï¼‰
        log_label = QLabel("ğŸ“‹ å¤„ç†æ—¥å¿—")
        f = log_label.font(); f.setBold(True); log_label.setFont(f)
        info_layout.addWidget(log_label, 4, 0, 1, 2)

        self.log_text = QTextEdit()
        self.log_text.setReadOnly(True)
        # å…è®¸æ›´çµæ´»çš„é«˜åº¦
        self.log_text.setMinimumHeight(180)
        font = QFontDatabase.systemFont(QFontDatabase.SystemFont.FixedFont)
        self.log_text.setFont(font)
        info_layout.addWidget(self.log_text, 5, 0, 1, 2)

        info_box.setContentLayout(info_layout)
        # é»˜è®¤å±•å¼€åˆ†æç»“æœé¢æ¿ï¼Œå±•å¼€å‘ä¸‹å»¶å±•
        info_box.toggle_button.setChecked(True)
        info_box._on_toggled(True)
        root_layout.addWidget(info_box)

        # åº•éƒ¨ä¼¸ç¼©
        root_layout.addStretch()

    def _connect_signals(self):
        """è¿æ¥ä¿¡å·"""
        pass

    def _select_audio(self):
        """é€‰æ‹©éŸ³é¢‘æ–‡ä»¶"""
        # é»˜è®¤ç›®å½• ../AE
        base_dir = os.path.dirname(os.path.abspath(__file__))
        default_dir = os.path.normpath(os.path.join(base_dir, "..", "AE"))
        path, _ = QFileDialog.getOpenFileName(
            self,
            "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
            default_dir if os.path.isdir(default_dir) else "",
            "éŸ³é¢‘æ–‡ä»¶ (*.wav *.mp3 *.flac);;æ‰€æœ‰æ–‡ä»¶ (*)"
        )
        if path:
            self.audio_path = path
            self.audio_path_edit.setText(Path(path).name)
            self._log(f"âœ“ å·²é€‰æ‹©éŸ³é¢‘: {Path(path).name}")
            # è‡ªåŠ¨å¼€å§‹åˆ†æ
            # è‹¥åˆ†æçº¿ç¨‹æ­£åœ¨è¿è¡Œåˆ™è·³è¿‡
            if not (self.analysis_worker and self.analysis_worker.isRunning()):
                self._analyze_audio()

    def _select_srt(self):
        """é€‰æ‹©å­—å¹•æ–‡ä»¶"""
        # é»˜è®¤ç›®å½• ./output
        base_dir = os.path.dirname(os.path.abspath(__file__))
        default_dir = os.path.normpath(os.path.join(base_dir, "output"))
        path, _ = QFileDialog.getOpenFileName(
            self,
            "é€‰æ‹©å­—å¹•æ–‡ä»¶",
            default_dir if os.path.isdir(default_dir) else "",
            "SRT å­—å¹• (*.srt);;æ‰€æœ‰æ–‡ä»¶ (*)"
        )
        if path:
            self.srt_path = path
            self.srt_path_edit.setText(Path(path).name)
            self._log(f"âœ“ å·²é€‰æ‹©å­—å¹•: {Path(path).name}")
            # è‹¥å·²æœ‰åˆ†æç»“æœåˆ™è‡ªåŠ¨åŒ¹é…ï¼›å¦åˆ™ç­‰å¾…åˆ†æå®Œæˆåè‡ªåŠ¨åŒ¹é…
            if self.current_silences:
                if not (self.matching_worker and self.matching_worker.isRunning()):
                    self._match_subtitles()

    def _analyze_audio(self):
        """åˆ†æéŸ³é¢‘"""
        if not self.audio_path:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
            return

        self._log("æ­£åœ¨åˆ†æéŸ³é¢‘...")
        self.progress_bar.setVisible(True)
        self.analyze_btn.setEnabled(False)

        self.analysis_worker = AnalysisWorker(
            self.audio_path,
            self.threshold_spin.value(),
            self.min_silence_spin.value()
        )
        self.analysis_worker.progress.connect(self._on_analysis_progress)
        self.analysis_worker.finished.connect(self._on_analysis_finished)
        self.analysis_worker.error.connect(self._on_analysis_error)
        self.analysis_worker.start()

    def _on_analysis_progress(self, msg: str):
        """å¤„ç†åˆ†æè¿›åº¦"""
        self._log(msg)

    def _on_analysis_finished(self, silences: List[Silence]):
        """åˆ†æå®Œæˆ"""
        self.current_silences = silences
        self.progress_bar.setVisible(False)
        self.analyze_btn.setEnabled(True)
        self.match_btn.setEnabled(True)

        # æ›´æ–°ç»Ÿè®¡
        total_silence = sum(s.duration for s in silences)
        self.silence_count_label.setText(str(len(silences)))
        self.total_silence_label.setText(f"{total_silence:.2f}s")

        # æ‰“å°åœé¡¿åˆ—è¡¨
        self._log("\næ£€æµ‹åˆ°çš„åœé¡¿:")
        for i, s in enumerate(silences, 1):
            self._log(f"  {i}. {s.start:.2f}s - {s.end:.2f}s (æ—¶é•¿: {s.duration:.2f}s)")

        # è‹¥å·²é€‰å®šå­—å¹•æ–‡ä»¶ï¼Œè‡ªåŠ¨å¼€å§‹åŒ¹é…
        if self.srt_path and not (self.matching_worker and self.matching_worker.isRunning()):
            self._match_subtitles()

    def _on_analysis_error(self, error: str):
        """åˆ†æå‡ºé”™"""
        self.progress_bar.setVisible(False)
        self.analyze_btn.setEnabled(True)
        self._log(f"âŒ é”™è¯¯: {error}")
        QMessageBox.critical(self, "åˆ†æé”™è¯¯", error)

    def _match_subtitles(self):
        """åŒ¹é…å­—å¹•"""
        # é˜²é‡å…¥
        if self.matching_worker and self.matching_worker.isRunning():
            return
        if not self.srt_path:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å­—å¹•æ–‡ä»¶")
            return

        if not self.current_silences:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆåˆ†æéŸ³é¢‘æ–‡ä»¶")
            return

        self._log("æ­£åœ¨åŒ¹é…å­—å¹•...")
        self.progress_bar.setVisible(True)
        self.match_btn.setEnabled(False)

        self.matching_worker = MatchingWorker(self.srt_path, self.current_silences)
        self.matching_worker.progress.connect(self._on_matching_progress)
        self.matching_worker.finished.connect(self._on_matching_finished)
        self.matching_worker.error.connect(self._on_matching_error)
        self.matching_worker.start()

    def _on_matching_progress(self, msg: str):
        """å¤„ç†åŒ¹é…è¿›åº¦"""
        self._log(msg)

    def _on_matching_finished(self, subtitles: List[SRTSubtitle], logs: str):
        """åŒ¹é…å®Œæˆ"""
        self.current_subtitles = subtitles
        self.progress_bar.setVisible(False)
        self.match_btn.setEnabled(True)
        self.export_btn.setEnabled(True)

        # æ›´æ–°ç»Ÿè®¡
        if subtitles:
            duration = subtitles[-1].end - subtitles[0].start
            self.original_duration_label.setText(f"{duration:.2f}s")
        self.subtitle_count_label.setText(str(len(subtitles)))

        # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        self._log(logs)

    def _on_matching_error(self, error: str):
        """åŒ¹é…å‡ºé”™"""
        self.progress_bar.setVisible(False)
        self.match_btn.setEnabled(True)
        self._log(f"âŒ é”™è¯¯: {error}")
        QMessageBox.critical(self, "åŒ¹é…é”™è¯¯", error)

    def _export_subtitles(self):
        """å¯¼å‡ºå­—å¹•"""
        if not self.current_subtitles:
            QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„å­—å¹•")
            return

        # ä½¿ç”¨æ‰€é€‰å­—å¹•æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œè‡ªåŠ¨å‘½åä¸º åŸå+replace.srt
        if not self.srt_path:
            QMessageBox.warning(self, "è­¦å‘Š", "å°šæœªé€‰æ‹©å­—å¹•æ–‡ä»¶ï¼Œæ— æ³•ç¡®å®šå¯¼å‡ºä½ç½®")
            return
        srt_dir = os.path.dirname(self.srt_path)
        base_name = Path(self.srt_path).stem + "replace.srt"
        save_path = os.path.join(srt_dir, base_name)

        try:
            SRTParser.save(save_path, self.current_subtitles)
            self._log(f"âœ“ å­—å¹•å·²ä¿å­˜: {save_path}")
            QMessageBox.information(self, "æˆåŠŸ", f"å­—å¹•å·²å¯¼å‡ºè‡³:\n{save_path}")
            self.export_btn.setEnabled(False)
        except Exception as e:
            self._log(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
            QMessageBox.critical(self, "å¯¼å‡ºé”™è¯¯", str(e))

    def _open_output(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•"""
        # æ‰“å¼€æ¡Œé¢æˆ–ç”¨æˆ·ç›®å½•
        home_dir = str(Path.home())
        os.startfile(home_dir)

    def _reset(self):
        """é‡ç½®"""
        self.audio_path = None
        self.srt_path = None
        self.current_silences = []
        self.current_subtitles = []

        self.audio_path_edit.clear()
        self.srt_path_edit.clear()
        self.log_text.clear()

        self.silence_count_label.setText("0")
        self.total_silence_label.setText("0.0s")
        self.subtitle_count_label.setText("0")
        self.original_duration_label.setText("0.0s")

        self.match_btn.setEnabled(False)
        self.export_btn.setEnabled(False)
        self.analyze_btn.setEnabled(True)

        self._log("å·²é‡ç½®")

    def _log(self, msg: str):
        """è®°å½•æ—¥å¿—"""
        self.log_text.append(msg)
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        self.log_text.verticalScrollBar().setValue(
            self.log_text.verticalScrollBar().maximum()
        )

    def _status(self, msg: str):
        """æ›´æ–°çŠ¶æ€"""
        self.status_label.setText(msg)


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def main():
    app = QApplication(sys.argv)
    
    # è®¾ç½®ä¸º Python å¯æ‰§è¡Œæ–‡ä»¶çš„å›¾æ ‡ï¼ˆpythonw.exeï¼‰
    try:
        python_exe = sys.executable  # pythonw.exe è·¯å¾„
        if os.path.exists(python_exe):
            icon = QIcon(python_exe)
            if not icon.isNull():
                app.setWindowIcon(icon)
    except Exception:
        pass
    
    window = SubtitlePauseMatcherUI()
    window.show()
    sys.exit(app.exec())


if __name__ == "__main__":
    main()
